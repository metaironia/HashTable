# Исследование работы хэш-таблицы с разрешением коллизий методом цепочек и ее низкоуровневая оптимизация

Сергей Кулагин, 1 курс ФРКТ МФТИ

Хэш-таблица - это такая структура данных, в которой вставка, поиск и удаление элемента происходит за $O(1)$ в лучшем случае. Выглядит она так (картинка взята [отсюда](https://khalilstemmler.com/blogs/data-structures-algorithms/hash-tables/)):

<img src=readme_images/hash_table_example.png width=40%>

### Общий принцип ее работы

Общий принцип ее работы таков: пусть мы вставляем элемент в хеш-таблицу. Как выбирается ячейка хэш-таблицы, в которую нужно вставить элемент? На вход хэш-функции поступает ключ (в данном случае слово), из которого хэш-функция получает некое числовое значение. Это числовое значение и будет являться номером ячейки хэш-таблицы, в которую следует положить элемент. 

Для поиска и удаления алгоритм выбора ячейки хэш-таблицы такой же.

### Устройство нашей хэш-таблицы 

В качестве ячейки хэш-таблицы будет использоваться самописный двусвязный список, обладающий свойством локальности и дружественный к кешу. Сама хэш-таблица будет представлять из себя массив таких двусвязных списков. 

        -- вставить картинку из инета
        -- Не, передумал
                                Внутренний монолог автора


#### Функции нашей хэш-таблицы

Удаление элемента из хэш-таблицы нас интересовать не будет, такой функции поддерживаться не будет. 

Будет поддерживаться вставка и поиск элемента в хэш-таблице. 
В качестве элемента будет выступать слово. 

Вставка будет происходить таким образом, чтобы два одинаковых слова в хэш-таблице не встречалось (в одной ячейке не может быть два одинаковых слова). Следует уточнить, что значение, полученное хэш-функцией, может превосходить размер хэш-таблицы. Чтобы решить эту проблему, номер ячейки хэш-таблицы будет являться остатком от деления значения хэш-функции на размер хэш-таблицы.

Поиск элемента будет происходить по общему алгоритма поиска в хэш-таблице.

## Первая часть работы

### Цель

Цель первой части работы заключается в исследовании распределения значений восьми хэш-функций. Подробнее см. ниже.

### Метод исследования

Для исследования будем использовать нашу хэш-таблицу. В качестве данных для вставки в хэш-таблицу возьмем набор слов, использующихся в произведении У.Шекспира "Гамлет, принц датский" (см. [hamlet.txt](src/hamlet.txt)). Это позволит нам исследовать поведение хэш-функций не на искусственно сгенерированных данных, а на реальных, что лучше. После вставки всех слов в хэш-таблицу необходимо будет сделать дамп заселенности хэш-таблицы. Используя этот дамп, будем строить диаграмму заселенности хэш-таблицы.

Работать будем с лоад-фактором (или заселенностью) хэш-таблицы около 7. Это позволит нам лучше исследовать поведение хэш-функций, так как диапазон значений хэш-функций (в среднем) больше размера хэш-таблицы.

### Скрипт, считающий количество слов в тексте

Мой скрипт будет из текста делать файл, в котором на каждой строке будет находиться одно слово, при этом убирая различные знаки препинания. Важно отметить, что слова в выходном файле скрипта могут повторяться.

В текстовом файле, который создал мой скрипт из текста произведения У.Шекспира "Гамлет, принц датский", примерно 5500 уникальных слов.

### Размер хэш-таблицы

Стоит обговорить и размер хэш-таблицы. Ее размер должен быть простым числом. Почему? 

Допустим, что хэш-функция чаще всего выдает значения, кратные 100. Тогда в списках с индексами, кратными 100, будет в среднем больше элементов. Предположим, что размер хэш-таблицы будет также равен 100. Возьмем списки с номерами 200, 300, ... Остатки от деления номеров этих списков на размер хэш-таблицы будут совпадать. Следовательно, их элементы попадут в одну ячейку хэш-таблицы, и длина списка, соответствующего этой ячейке, будет равна сумме длин исходных списков. Поэтому в этой ячейке будет еще больше элементов, и на гистограмме будет усиливаться пик заселенности в этой ячейке. Строго говоря, усиление будет происходить для любых пиков, повторяющихся с периодом k, если у k и размера хэш-таблицы будет общий множитель. Чтобы минимизировать такую вероятность, размер хэш-таблицы стоит выбирать как простое число. Это позволит избежать усиления пиков заселенности.  

В нашем случае для того, чтобы лоад-фактор хэш-таблицы был ~= 7, размер хэш-таблицы будет равен 787.

### Исследуемые хэш-функции

### Первая хэш-функция (`ConstHash()`)

Код первой хэш-функции выглядит так:

```c
uint32_t ConstHash (const HashTableElem_t value) {

    return 0;
}
```

То есть она всегда возвращает 0 вне зависимости от входной строки.

Диаграмма распределения такой хэш-функции:

![const_hash](<readme_images/Hash table load histogram (ConstHash()).png>)

Дисперсия такого распределения:
```
Const hash:
variance of elements in hash table = 38213.79
```

Понятно, что эта функция никуда не годится.

### Вторая хэш-функция (`FirstSymHash()`)

Код второй хэш-функции:
```c
uint32_t FirstSymHash (const HashTableElem_t value) {

    return ((int64_t) value[0]);
}
```

Она возвращает ASCII-код первой буквы слова. 

Диаграмма распределения такой хэш-функции:

![FirstSymHash](<readme_images/Hash table load histogram (FirstSymHash()).png>)

Дисперсия такого распределения:
```
First symbol hash:
variance of elements in hash table = 1516.97
```

По сравнению с первой хэш-функцией уже лучше, однако такое распределение все так же никуда не годится.

### Третья хэш-функция (`LenHash()`)

Код третьей хэш-функции:
```c
uint32_t LenHash (const HashTableElem_t value) {

    return ((uint32_t) strlen (value));
}
```

Она возвращает длину слова.

Диаграмма распределения такой хэш-функции:

![len_hash](<readme_images/Hash table load histogram (LenHash()).png>)

Видно, что значения 40 и более хэш-функция не возвращает, поэтому построим приближенную по оси x гистограмму: 

![len_hashSzoom](<readme_images/Hash table load histogram (LenHash()) zoomed.png>)

Дисперсия такого распределения:
```
Length hash:
variance of elements in hash table = 5136.29
```

Сильно неравномерная хэш-функция с ярко выраженным пиком в начале. Не стоит ее использовать. 

### Четвертая хэш-функция (`AsciiSumHash()`)

Код четвертой хэш-функции:
```c
uint32_t AsciiSumHash (const HashTableElem_t value) {

    uint32_t ascii_codes_sum = 0;
    uint32_t word_length     = (uint32_t) strlen (value);

    for (size_t i = 0; i < word_length; i++)
        ascii_codes_sum += value[i];

    return ascii_codes_sum;
}
```
Она возвращает сумму всех ASCII-кодов слова.

Исследование этой хэш-функции будет производиться в двух случаях: 
1. При размере хэш-таблицы = 787;
2. При размере хэш-таблицы = 101.

#### Часть 1

Исследование при лоад-факторе хэш-таблицы ~=7.

Диаграмма распределения такой хэш-функции:

![ascii_sum_787](<readme_images/Hash table load histogram (AsciiSumHash()) 787.png>)

Дисперсия такого распределения:
```
Ascii sum hash, load factor ~= 7:
variance of elements in hash table = 33.95 
```

Отличная хэш-функция, судя по дисперсии. Но если обратить внимание на пики, то отличной ее назвать язык не повернется. Но самое главное, что эта функция коварна: она ограничена сверху, так как не существует таких длинных слов с большой суммой. Это приводит к тому, что теряется главное свойство хэш-таблицы: увеличивая ее размер, мы уменьшаем лоад-фактор и ускоряем поиск. Масштабирование по размеру в данном случае невозможно. 

#### Часть 2

Исследование при размере хэш-таблицы = 101.

Диаграмма распределения такой хэш-функции:

![101_ascii_hash](<readme_images/Hash table load histogram (AsciiSumHash()) 101.png>)    

Дисперсия такого распределения:
```
Ascii sum hash, hash table capacity = 101:
variance of elements in hash table = 463.25 
```

Распределение не совсем равномерное, но лучше всех рассмотренных выше хэш-функций. Ее можно было бы использовать для хэш-таблиц размером до ~100 ячеек, но из-за гигантского лоад-фактора хэш-таблицы лучше не использовать эту хэш-функцию.

### Пятая хэш-функция (`AsciiSumDivLenHash()`)

Код пятой хэш-функции:
```c
uint32_t AsciiSumDivLenHash (const HashTableElem_t value) {

    uint32_t ascii_codes_sum = 0;

    uint32_t word_length = (uint32_t) strlen (value);

    for (size_t i = 0; i < word_length; i++)
        ascii_codes_sum += value[i];

    return ((uint32_t) (ascii_codes_sum / word_length));
}
```

Она возвращает округленный до целого результат деления суммы всех ASCII-кодов слова на длину слова.

Диаграмма распределения такой хэш-функции:

![ascii_sum_div_len_hash](<readme_images/Hash table load histogram (AsciiSumDivLenHash()).png>)

Дисперсия такого распределения:
```
Ascii sum div len hash:
variance of elements in hash table = 2597.03 
```

Видно, что эта хэш-функция обладает ярко выраженным пиком и далеко не равномерным распределением. Не стоит ее использовать.

### Шестая хэш-функция (`RorHash()`)

Код шестой хэш-функции:
```c
uint32_t RorHash (const HashTableElem_t value) {

    uint32_t word_length = (uint32_t) strlen (value);

    if (word_length == 0)
        return 0;

    uint32_t hash = value[0];

    for (size_t i = 1; i <= word_length; i++) {

        hash = MyRor (hash, 1);
        hash ^= value[i];
    }

    return hash;
}
```

`MyRor()` - функция, выполняющая циклический побитовый сдвиг вправо. Так, например, `MyRor(a, b)` выполнит циклический сдвиг вправо на `b` позиций над числом `a` и вернет получившееся число.

Диаграмма распределения такой хэш-функции:

![ror_hash](<readme_images/Hash table load histogram (RorHash()).png>)

Хэш-функция обладает не очень равномерным распределением. В принципе, использовать ее можно, но можно найти вариант лучше. 

Дисперсия такого распределения:
```
Ror hash:
variance of elements in hash table = 21.34  
```

### Седьмая хэш-функция (`RolHash()`)

Код седьмой хэш-функции ничем не отличается от шестой за исключением того, что вместо `MyRor` в ней используется `MyRol`:
```c
uint32_t RolHash (const HashTableElem_t value) {

    uint32_t word_length = (uint32_t) strlen (value);

    if (word_length == 0)
        return 0;

    uint32_t hash = value[0];

    for (size_t i = 1; i <= word_length; i++) {

        hash = MyRol (hash, 1);
        hash ^= value[i];
    }

    return hash;
}
```

`MyRol()` - функция, выполняющая циклический побитовый сдвиг влево.

Диаграмма распределения такой хэш-функции:

![rol_hash](<readme_images/Hash table load histogram (RolHash()).png>)

Распределение выглядит довольно равномерно, оно без особо ярко выраженных пиков. Функция пригодна к использованию в реальных задачах.  

Дисперсия такого распределения:
```
Rol hash:
variance of elements in hash table = 8.89   
```


### _Интересный факт про оптимизацию `MyRol()` и `MyRor()`_

Оказывается, функции `MyRor()` и `MyRol()` компилятор при любом флаге оптимизации может свернуть в ассемблерные команды ror и rol соответственно (пример для -O3):

<img src=readme_images/ror_rol_o3.png width=65%>

### Восьмая хэш-функция (`MurmurHash()`)

В качестве восьмой хэш-функции будет выступать MurmurHash3_32. Сид у такой хэш-функции будет постоянен и равен 0.

Код этой хэш-функции:
```c
uint32_t MurmurHash (const HashTableElem_t value) {

    const uint8_t *key  = (const uint8_t *) value;

    const uint32_t len = (size_t) strlen ((char *) key);

    uint32_t hash             = 0;
    uint32_t four_bytes_block = 0;

    for (uint32_t i = len / 4; i > 0; i--) {

        memcpy (&four_bytes_block, key, sizeof (uint32_t));

        key += sizeof (uint32_t);

        four_bytes_block *= MAGIC_NUM_1;
        four_bytes_block  = MyRol (four_bytes_block, MAGIC_NUM_FOR_ROL_1);
        four_bytes_block *= MAGIC_NUM_2;

        hash ^= four_bytes_block;
        hash  = MyRol (hash, MAGIC_NUM_FOR_ROL_2);
        hash  = hash * MAGIC_NUM_6 + MAGIC_NUM_3;
    }

    four_bytes_block = 0;

    for (uint32_t i = len % 4; i > 0; i--) {

        four_bytes_block <<= 8;
        four_bytes_block  |= key [i - 1];
    }

    four_bytes_block *= MAGIC_NUM_1;
    four_bytes_block  = MyRol (four_bytes_block, MAGIC_NUM_FOR_ROL_1);
    four_bytes_block *= MAGIC_NUM_2;

    hash ^= four_bytes_block;

    hash ^= len;

    hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_1);
    hash *= MAGIC_NUM_4;
    hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_2);
    hash *= MAGIC_NUM_5;
    hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_1);

    return hash;
}
```

Диаграмма распределения такой хэш-функции:

![murmurhash](<readme_images/Hash table load histogram (MurmurHash()).png>)

Хэш-функция показывает равномерное распределение и отсутствие пиков. Отличная хэш-функция для реальных задач.

Дисперсия такого распределения:
```
Murmur hash:
variance of elements in hash table = 6.93  
```

Можно заметить, что эта хэш-функция показывает лучшее распределение среди представленных в этой работе.


### Вывод о распределениях этих хэш-функций

Таблица дисперсий исследуемых хэш-функций:

| Хэш-функция           | Дисперсия           |
| :-------------------------: | :-----------------: |
| `ConstHash()`                              | $38214$  |
| `LenHash()`                                | $5136$  |
| `AsciiSumDivLenHash()`                     | $2597$  |
| `FirstSymHash()`                           | $1517$  |
| `AsciiSumHash()`, размер хэш-таблицы = 101 | $463.3$  |
| `AsciiSumHash()`, лоад-фактор ~= 7         | $33.95$           |
| `RorHash()`                                | $21.34$           |
| `RolHash()`                                | $8.89$           |
| `MurmurHash()`                             | $6.93$           |

Видно, что `ConstHash()` надо использовать ... примерно никогда. Дисперсия этой хэш-функции очень велика, и поиск в хэш-таблице будет выполняться очень медленно. Между тем, `MurmurHash()` показал наименьший результат по дисперсии. Это означает, что эта хэш-функция отлично подходит для ее применении в хэш-таблицах.

## Вторая часть работы

### Цель

Во второй части работы необходимо оптимизировать поиск по хэш-таблице (сделать его быстрее). Необходимо сделать как минимум 3 оптимизации, используя 3 разных инструмента:
- встроенный в C ассемблер;
- внешний ассемблер;
- intrinsic функции.

Производительность до и после оптимизаций будем замерять как профилировщиком, так и функцией `rdtsc()` (речь об этом пойдет ниже). Замеры будут производиться 3 раза для получение более точного результата и выяснения влияние погрешности на эти замеры.

### Вычислительная машина и компилятор

В качестве вычислительной машины для замера производительности использовался ноутбук Toshiba Z930 Portege-DLS, в котором стоит процессор Intel Core i5 3317U архитектуры Ivy Bridge с базовой тактовой частотой 1.7 ГГц (2.6 ГГц в режиме Turbo Boost). 

В качестве компиляторов будут использоваться GCC версии 11.2 и MSVC версии 143.

#### GCC

При компиляции с помощью компилятора GCC будем использовать следующие флаги:

| Флаги  | Зачем использованы |
| --- | --------------- |
| `-O3`  | Для максимальной оптимизации кода компилятором |
| `-mavx`| Для использования расширенных векторных инструкций |
| `-DNDEBUG` | Для отключения `assert()` |

#### MSVC

Параметры компилятора MSVC:

<img src=readme_images/msvc_settings.png width=55%>

### Замеры производительности

В качестве средства профилирования будет использоваться Visual Studio Community 2022 в режиме, показанном на изображении:

<img src=readme_images/profiler_main.png width=55%>

Помимо этого, для замера производительности также будет использоваться `rdtsc()`. Она возвращает число тактов, прошедших с момента последнего сброса процессора. Функция `rdtsc()` до начала бенчмарка и сразу после него:

```c
int64_t cycle_start = __rdtsc();
 
HashTableFindBenchmark (&hash_table, &words_from_file);

int64_t cycle_end = __rdtsc();
```

Таким образом, мы сможем получить количество циклов, затраченных на бенчмарк. Сам бенчмарк будет производиться так: все слова, которые находятся в хэш-таблице, будут искаться 20000 раз:

```c
for (size_t i = 0; i < MAX_BENCHMARK_COMP_NUM; i++) { // 20000 iterations

    char *volatile curr_word = (words -> word);

    for (size_t word_num = 0; word_num < ((size_t) words -> num_of_words); word_num++) {

        HashTableFind (hash_table, curr_word);
        curr_word += MAX_WORD_LENGTH;
    }
}
```

Многократный поиск слов позволит снизить влияние внешних факторов (системные прерывания, различные случайные промахи) на случайную погрешность времени бенчмарка.

### Сравнение GCC и MSVC

По ходу работы будем сравнивать скорость кода, который генерирует GCC (используя вышеперечисленные флаги) и MSVC (на версии "Release") с помощью нашего бенчмарка. Для этого будем делать 2 таблицы с измерениями. В одной таблице будет производительность кода, сгенерированным GCC, в другой - сгенерированным MSVC. 

### Насчет троттлинга

Если во время бенчмарка начался троттлинг, то результаты измерений с помощью `rdtsc()` на самом деле недостоверны. Чтобы избежать пропуска тактов из-за перегрева процессора, возможное появление троттлинга во время бенчмарка будем отслеживать с помощью программы AIDA64.

По данным с сайта [Intel](https://www.intel.com/content/www/us/en/products/sku/65707/intel-core-i53317u-processor-3m-cache-up-to-2-60-ghz/specifications.html), 105°C - это температура нашего процессора, выше которой кристалл умирает. На самом деле, троттлинг начинается с температуры 100°C. Будем следить, чтобы такая температура не достигалась при бенчмарке.

---

### Производительность до оптимизаций

Замерим производительность бенчмарком до различных оптимизаций. 

Результаты измерений скорости кода, сгенерированным GCC:

| Номер измерения | Затрачено циклов       |
| :-------------: | :--------------------: |
| 1               | $1.48 \cdot 10^{11}$ |
| 2               | $1.57 \cdot 10^{11}$ |
| 3               | $1.54 \cdot 10^{11}$ |

Среднее число затраченных циклов = $1.53 \cdot 10^{11}$. Погрешность среднего составляет $2.66 \cdot 10^9$. Видно, что погрешность составляет $\approx 2\%$. Заметим, что троттлинга во время теста не наблюдалось:

<img src=readme_images/aida_gcc_noopt..png width=60%>


Результаты измерений скорости кода, сгенерированным MSVC:

| Номер измерения | Затрачено циклов       |
| :-------------: | :--------------------: |
| 1               | $1.48 \cdot 10^{11}$ |
| 2               | $1.51 \cdot 10^{11}$ |
| 3               | $1.50 \cdot 10^{11}$ |

Среднее число затраченных циклов = $1.50 \cdot 10^{11}$. Погрешность среднего составляет $6.48 \cdot 10^8$. 

Троттлинга также не наблюдалось:

<img src=readme_images/aida_msvc_noopt.png width=60%>

**Получается, что код, сгенерированный MSVC, эффективнее, чем код, сгенерированный GCC?** Да, в данный момент это так.

---

### Про троттлинг в нашем случае

На самом деле, при дальнейших измерениях троттлинг не будет возникать, и следить за возможным его возникновением бессмысленно. Чтобы убедиться в этом, запустим тест в AIDA64 с такими параметрами на 10 мин: 

<img src=readme_images/aida_test_params.png width=15%>

По прошествии 10 минут можно видеть, что никакого троттлинга при максимальной нагрузке не было, а температура во время стресс-теста не поднималась выше 75°C.

<img src=readme_images/stress_test.png width=60%>


---

#### Профилировщик

Говоря о профилировщике, он показывает, что характерное время выполнения программы - около 1 минуты и 30 секунд:

<img src=readme_images/1-30_sec_noopt.png width=60%>

Из них на бенчмарк ушло ~70 секунд (общее время минус собственное время для `HashTableTestFind()`):

<img src=readme_images/noopt_bench_profile.png width=60%>

Некоторые функции, вызывающиеся при бенчмарке, вызываются также и до вызова функции бенчмарка. Большое время выполнения бенчмарка (~70 сек, при том что время работы всей программы ~88 сек) как раз позволяет пренебречь этой погрешностью в измерениях.

### Что оптимизировать?

Попытаемся понять, что можно оптимизировать в этой программе. По показаниям профилировщика, большая часть времени уходит на поиск элемента в списке, а говоря точнее, на `strcmp()`:

<img src=readme_images/strcmp.png width=60%>

Вторая функция, которую можно будет оптимизировать - это `MurmurHash()`:

<img src=readme_images/murmurhash.png width=60%>

В ней нельзя выделить только одно сильно затратное место, поэтому речь об ее оптимизации пойдет в несколько другом ключе.

### Внешний ассемблер

Будем оптимизировать `strcmp()` в функции поиска элемента в списке. Как это можно сделать?

Можно заметить, что слова, использующиеся в речи и письме, не содержат более 32 символов. Так как каждый символ - это 8 бит, то возникает идея реализовать `strcmp()` при помощи ymm регистров. Два слова можно положить в два ymm регистра (так как каждое слово не более 256 бит), после чего сравнить эти два регистра. Чтобы слова можно было класть в регистры и сравнивать, стоит каждое слово дополнять нулевыми байтами до размера в 32 байта. Это позволит не сравнивать мусор, находящийся после нулевого терминатора. Также это позволит избежать segmentation fault.

Тогда реализация `strcmp()` на внешнем ассемблере (nasm) будет выглядеть так:

```asm
MyStrcmp:   vlddqu ymm1, [rcx]
            vptest ymm1, [rdx]
            xor rax, rax
            setc al
            ret
```

Результаты измерения скорости кода, сгенерированного GCC:

| Номер измерения | Затрачено циклов       |
| :-------------: | :--------------------: |
| 1               | $5.29 \cdot 10^{10}$ |
| 2               | $5.16 \cdot 10^{10}$ |
| 3               | $5.08 \cdot 10^{10}$ |

Среднее число затраченных циклов = $5.18 \cdot 10^{10}$. Погрешность среднего составляет $6.29 \cdot 10^8$. 

Результаты измерения скорости кода, сгенерированного MSVC:

| Номер измерения | Затрачено циклов       |
| :-------------: | :--------------------: |
| 1               | $5.55 \cdot 10^{10}$ |
| 2               | $5.41 \cdot 10^{10}$ |
| 3               | $5.45 \cdot 10^{10}$ |

Среднее число затраченных циклов = $5.47 \cdot 10^{10}$. Погрешность среднего составляет $4.15 \cdot 10^8$.

Видно, что производительность кода MSVC стала уступать производительности кода GCC.

Прирост производительности после замены стандартного `strcmp()` на `MyStrcmp()`колоссальный: он составляет x $2.95$
по сравнению с производительностью программы без оптимизаций.

По данным профилировщика видно, что среднее время работы программы сократилось до примерно 35 секунд:

<img src=readme_images/after_1_opt.png width=60%>

### Встроенный в C ассемблер

Вторая функция, которую можно оптимизировать - это `strlen()` в `Murmurhash()`. На самом деле, нам очень сильно повезло, что в нашем датасете нет слов больше, чем 16 символов (максимальная длина слова - всего 14 букв). Это означает, что можно попробовать реализовать `strlen()`, который будет использовать векторные инструкции типа AVX и не будет использовать инструкции типа AVX-2 (мой компьютер попросту не поддерживает AVX-2).   

Код самодельного `strlen()` на встроенном ассемблере будет выглядеть так:

```c
asm volatile ("vlddqu xmm1, [%1]\n\t"
              "vpxor xmm2, xmm2, xmm2\n\t"
              "vpcmpeqb xmm1, xmm1, xmm2\n\t"
              "vpmovmskb %0, xmm1\n\t"
              "tzcnt %0, %0"
              : "=X" (len)
              : "r" (value));
```
    
Результаты измерения скорости кода, сгенерированного GCC:

| Номер измерения | Затрачено циклов       |
| :-------------: | :--------------------: |
| 1               | $4.59 \cdot 10^{10}$ |
| 2               | $4.52 \cdot 10^{10}$ |
| 3               | $4.54 \cdot 10^{10}$ |

Среднее число затраченных циклов = $4.55 \cdot 10^{10}$. Погрешность среднего составляет $2.07 \cdot 10^8$.

К сожалению, профилировщиков в данном случае воспользоваться не получится. В ассемблерной вставке используется синтаксис, поддерживаемый только расширением GCC. 

Тут, между прочим, и вылезает главная проблема оптимизаций - это их непереносимость.

Таблица производительности:

| Оптимизация | Абсолютное ускорение | Относительное ускорение (относительно предыдущей версии программы)
| :-------------: | :------: | :------: |
| `strcmp()`  | x $2.95$ | x $2.95$ |
| `strlen()`  | x $3.36$ | x $1.14$ |

### Intrinsic функции

Как было видно выше, `MurmurHash()` занимает довольно много процессорного времени. Понятно, что необходимо как-то уменьшить это время, и только оптимизацией `strlen()` тут не обойтись. Специально для такого случая существует хэш-функция crc32, которая реализуется на аппаратном уровне. Если в нашем случае заменить `MurmurHash()` на аппаратно реализуемый crc32, то скорее всего, будет серьезный прирост. Проверим, так ли это.

Слова в нашем датасете содержат не более 16 символов (16 байт). Это означает, что для полного хеширования слова необходимо применить 2 раза функцию хэширования crc32. Код хэш-функции, реализованной на intrinsic crc32, будет выглядеть так: 

```c
uint32_t IntrinsicCrc32 (const HashTableElem_t value) {

    uint32_t crc = _mm_crc32_u64(0ULL, *( (uint64_t *) value));
                   _mm_crc32_u64(crc,  *(((uint64_t *) value) + 1));

    return crc;
}
```

Результаты измерения скорости кода, сгенерированного GCC:

| Номер измерения | Затрачено циклов       |
| :-------------: | :--------------------: |
| 1               | $2.54 \cdot 10^{10}$ |
| 2               | $2.48 \cdot 10^{10}$ |
| 3               | $2.57 \cdot 10^{10}$ |

Среднее число затраченных циклов = $2.53 \cdot 10^{10}$. Погрешность среднего составляет $2.70 \cdot 10^8$. 

Результаты измерения скорости кода, сгенерированного MSVC:

| Номер измерения | Затрачено циклов       |
| :-------------: | :--------------------: |
| 1               | $2.98 \cdot 10^{10}$ |
| 2               | $2.97 \cdot 10^{10}$ |
| 3               | $2.90 \cdot 10^{10}$ |

Среднее число затраченных циклов = $2.95 \cdot 10^{10}$. Погрешность среднего составляет $2.45 \cdot 10^8$. 

MSVC в скорости сгенерированного кода все также проигрывает коду, который сгенерировал GCC.

Опять же, эта оптимизация дала колоссальный прирост производительности. Тут уже можно воспользоваться профилировщиком для оценки времени работы программы:

<img src=readme_images/after_3_opt.png width=60%>

Время работы составило примерно 20 секунд.

Таблица относительного прироста производительности (для кода GCC):

| Оптимизация | Абсолютное ускорение | Относительное ускорение (относительно предыдущей версии программы)
| :-------------: | :------: | :------: |
| `strcmp()`  | x $2.95$ | x $2.95$ |
| `strlen()`  | x $3.36$ | x $1.14$ |
| Встроенная crc32 хэш-функция  | x $6.05$ | x $1.80$ |

### Оценка систематической погрешности

Оценим количество тактов, которое при тестировании скорости поиска тратится на переход в цикле, увеличение переменных и т.д. Тогда тело функции `HashTableFindBenchmark()` будет состоять из такого кода:
```c
for (size_t i = 0; i < MAX_BENCHMARK_COMP_NUM; i++) {

    char *volatile curr_word = (words -> word);

    for (size_t word_num = 0; word_num < ((size_t) words -> num_of_words); word_num++) {

        //HashTableFind (hash_table, curr_word);
        curr_word += MAX_WORD_LENGTH;
    }
}
```
Спецификатор volatile предотвратит выбрасывание кода компилятором. Результаты такого теста приведены в таблице.
| Номер теста | Затрачено циклов   |
|:-----------:|:------------------:|
| 1           | $2.05 \cdot 10^8$  |
| 2           | $2.08 \cdot 10^8$  |
| 3           | $2.13 \cdot 10^8$  |

Среднее количество циклов по результатам теста = $2.08 \cdot 10^8$. Видно, что погрешность наших предыдущих измерений в таком случае составляет $<1 \%$. 

## Вывод

Были проанализированы распределения значений различных хэш-функций, также были сделаны 3 различных оптимизации кода, позволившие сильно ускорить быстродействие программы. Необходимо помнить, что ассемблерные оптимизации могут и дать большой прирост к производительности, но он будет осуществляться за счет повышения непереносимости программы.

